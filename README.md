# miniGPT

Une impl√©mentation d'un mod√®le de langage de type GPT entra√Æn√© sur des donn√©es Wikip√©dia en fran√ßais.

## üìã Sommaire

* [Description](#description)
* [Architecture](#architecture)
* [Dataset](#dataset)
* [Entra√Ænement](#entra√Ænement)
* [G√©n√©ration](#g√©n√©ration)
* [Installation](#installation)

## Description

Ce projet impl√©mente un mod√®le de langage g√©n√©ratif bas√© sur l'architecture Transformer, similaire √† GPT-2. Le mod√®le est entra√Æn√© sur un corpus de textes fran√ßais issus de Wikip√©dia et peut g√©n√©rer du texte coh√©rent en fran√ßais.

## Architecture

## Dataset

Le dataset est compos√© d'articles Wikip√©dia en fran√ßais :

### Caract√©ristiques
- **Source** : Wikipedia FR (dump 2022)
- **Format** : Fichiers .npy contenant des tokens
- **Tokenizer** : tiktoken (compatible GPT-2)
- **Vocabulaire** : 50304 tokens

### Structure
- **Train** : Shards d'entra√Ænement (train-*.npy)
- **Val** : Shards de validation (val-*.npy)
- **Taille des shards** : ~10M tokens par fichier
